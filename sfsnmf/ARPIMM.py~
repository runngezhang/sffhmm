#!/usr/bin/python
#

import numpy as np
import time
import warnings

from numpy.random import randn
from string import join

import scipy.linalg as la

def medianWeightedFilter(energy, weights, scope=10):
    N = energy.size
    energyFiltered = np.copy(energy)
    for n in range(N):
        energyFrame = energy[np.maximum(n-scope,0):n+scope]
        weightsFrame = weights[np.maximum(n-scope,0):n+scope]
        energyFiltered[n] = np.median(weightsFrame[energyFrame>0] * \
                                      energyFrame[energyFrame>0]) / \
                                      sum(weightsFrame[energyFrame>0])
        if np.isnan(energyFiltered[n]):
            energyFiltered[n] = energy[n] 
    return energyFiltered

def medianFilter(energy, scope=10):
    N = energy.size
    energyFiltered = np.copy(energy)
    for n in range(N):
        energyFrame = energy[np.maximum(n-scope,0):n+scope]
        energyFiltered[n] = np.median(energyFrame[energyFrame>0])
        if np.isnan(energyFiltered[n]):
            energyFiltered[n] = energy[n] 
    return energyFiltered

def db(positiveValue):
    """
    db(positiveValue)

    Returns the decibel value of the input positiveValue
    """
    return 10 * np.log10(np.abs(positiveValue))

def ISDistortion(X,Y):
    """
    value = ISDistortion(X, Y)

    Returns the value of the Itakura-Saito (IS) divergence between
    matrix X and matrix Y. X and Y should be two NumPy arrays with
    same dimensio.n
    """
    return np.sum((-np.log(X / Y) + (X / Y) - 1))

def normalDistribution(vector, mu, sigma):
    return 1 / (np.sqrt(2.0 * np.pi * sigma**2))\
           * np.exp(- ((vector - mu) ** 2) / (2.0 * sigma ** 2))

def normalDistributionMat(matrix, muMat, sigma):
    return 1 / (np.sqrt(2.0 * np.pi * np.outer(np.ones(matrix.shape[0]), sigma**2))) * np.exp(- ((matrix - np.outer(np.ones(matrix.shape[0]), muMat)) ** 2) / (2.0 * np.outer(np.ones(matrix.shape[0]), sigma**2)))

# from scikits.learn.mixture, but without checking the min value:
def normalize(A, axis=None):
    """normalize(A, axis=None)
    
    Normalizes the array A by dividing its elements such that
    the sum over the given axis equals 1, except if that sum is 0,
    in which case, it ll stay 0.
    
    Parameters
    ----------
    A : ndarray
        An array containing values, to be normalized.
    axis : integer, optional
        Axis over which the ndarray is normalized. By default, axis
        is None, and the array is normalized such that its sum becomes 1.
    
    Returns
    -------
    out : ndarray
        The normalized ndarray.
    
    See also
    --------
    scikits.learn.normalize

    Examples
    --------
    >>> normalize(np.array([[0., 1.], [0., 5.]]))
    array([[ 0.        ,  0.16666667],
           [ 0.        ,  0.83333333]])
    >>> normalize(np.array([[0., 1.], [0., 5.]]), axis=0)
    array([[ 0.        ,  0.16666667],
           [ 0.        ,  0.83333333]])
    
    """
    Asum = A.sum(axis)
    if not(axis is None) and A.ndim > 1:
        # Make sure we don't divide by zero.
        Asum[Asum == 0] = 1
        shape = list(A.shape)
        shape[axis] = 1
        Asum.shape = shape
    else:
        if Asum==0:
            Asum  = 1
    return A / Asum

# Formant-Tracking AutoRegressive Filters + IMM
def FoTARFIMM(# the data to be fitted to:
         SX,
         # the basis matrices for the spectral combs
         WF0,
         # and for the elementary filters:
         WPHI0, poleFrq,
         numberOfFormants,
         numberOfAmpPerFormantFreq,
         # number of desired filters, accompaniment spectra:
         numberOfAccompanimentSpectralShapes=10,
         # if any, initial amplitude matrices for 
         HPHI0=None,
         HF00=None,
         WM0=None, HM0=None,
         # Some more optional arguments, to control the "convergence"
         # of the algo
         numberOfIterations=1000, updateRulePower=1.0,
         stepNotes=4, 
         lambdaHF0=0.00,alphaHF0=0.99,
         displayEvolution=False, verbose=True):
    
    eps = 10 ** (-50)
    
    if displayEvolution:
        import matplotlib.pyplot as plt
        from imageMatlab import imageM
        plt.ion()
        print "Is the display interactive? ", plt.isinteractive()
        
    # renamed for convenience:
    R = numberOfAccompanimentSpectralShapes
    omega = updateRulePower
    
    F, N = SX.shape
    Fwf0, NF0 = WF0.shape
    Fwphi, K = WPHI0.shape
    
    ## speeding up computations?
    WF0T = WF0.T.copy()    # C contiguous tranposed matrix
    WPHIT = WPHI0.T.copy() # idem
    
    # Checking the sizes of the matrices
    if Fwf0 != F:
        return False # A REVOIR!!!
    
    if HPHI0 is None: # default behaviour
        HPHI = np.abs(randn(K, N))
    else:
        Khphi0, Nhphi0 = np.array(HPHI0).shape
        if Khphi0 != K or Nhphi0 != N:
            print "Wrong dimensions for given HPHI0, \n"
            print "random initialization used instead"
            HPHI = np.abs(randn(K, N))
        else:
            HPHI = np.array(HPHI0)
            
    nbIterAdaptFormant = numberOfIterations
    nbElPerFormant = K / numberOfFormants
    varFormant0 = nbElPerFormant / 2.0# in the beginning, allow wide spread in formant
    varFormant8 = numberOfAmpPerFormantFreq / 6.0
    # in the end, variance per formant should be size of one
    sigmaFormant = varFormant0 ** 2 + \
                   (varFormant8 ** 2 - varFormant0 ** 2) * \
                   np.arange(1, nbIterAdaptFormant + 1) / np.double(nbIterAdaptFormant)
    formantRanges = {}
    for n in range(numberOfFormants):
        formantRanges[n] = n*nbElPerFormant + np.arange(nbElPerFormant)
        HPHIfo = HPHI[formantRanges[n], :]
        sumHPHIfo = HPHIfo.sum(axis=0)
        HPHIfo = HPHIfo / np.outer(np.ones(nbElPerFormant), sumHPHIfo)
        mu = np.argmax(HPHIfo, axis=0)# np.dot(np.arange(nbElPerFormant), HPHIfo)
        # weighted mean, computed as value * nb_occurrences
        sigmaFormant0 = varFormant0 ** 2
        HPHIfo = 1 / np.sqrt(2.0*np.pi*np.outer(np.ones(nbElPerFormant), sigmaFormant0)) * \
                 np.exp(- 0.5 * ((np.outer(np.arange(nbElPerFormant), np.ones(N)) - \
                                  np.outer(np.ones(nbElPerFormant), mu)) ** 2) / \
                        np.outer(np.ones(nbElPerFormant), sigmaFormant0))
        HPHI[formantRanges[n], :] = HPHIfo * HPHI[formantRanges[n], :] / \
                                    np.outer(np.ones(nbElPerFormant), HPHIfo.max(axis=0))
        ## HPHIfo * np.outer(np.ones(nbElPerFormant), sumHPHIfo)
        
    # a mapping from one formant to the other, from frequency point of view:
    mapFormantToOther = np.zeros([K, numberOfFormants])
    matDist = (np.outer(poleFrq, np.ones(K)) - \
               np.outer(np.ones(K), poleFrq)) ** 2
    for n in range(numberOfFormants):
        mapFormantToOther[:,n] = np.argmin(matDist[:,formantRanges[n]], axis=1) + \
                                 formantRanges[n][0]
    
    rangeInMapping = np.int32(np.outer(np.ones(numberOfFormants), np.arange(N)))
    rangeInRemapping = np.int32(np.outer(np.arange(numberOfFormants), np.ones(N)))
    del matDist
    
    if HF00 is None:
        HF00 = np.abs(randn(NF0, N))
    else:
        if np.array(HF00).shape[0] == NF0 and np.array(HF00).shape[1] == N:
            HF00 = np.array(HF00)
        else:
            print "Wrong dimensions for given HF00, \n"
            print "random initialization used instead"
            HF00 = np.abs(randn(NF0, N))
    HF0 = HF00
    nbIterAdaptF0 = numberOfIterations / 2.0
    varF00 = NF0 / 1.0# in the beginning, allow wide spread in formant
    varF08 = stepNotes / 2.0# in the end, variance per note should be size of one semitone
    sigmaF0 = varF00 ** 2 + \
                   (varF08 ** 2 - varF00 ** 2) * \
                   np.arange(1, nbIterAdaptF0 + 1) / np.double(nbIterAdaptF0)
    HF0fo = np.copy(HF0)
    sumHF0fo = HF0fo.sum(axis=0)
    HF0fo = HF0fo / np.outer(np.ones(NF0), sumHF0fo)
    muF0 = np.argmax(HF0fo, axis=0)## np.dot(np.arange(NF0), HF0fo)
    # weighted mean, computed as value * nb_occurrences
    sigmaF00 = varF00 ** 2
    HF0fo = 1 / np.sqrt(2.0*np.pi*np.outer(np.ones(NF0), sigmaF00)) * \
            np.exp(- 0.5 * ((np.outer(np.arange(NF0), np.ones(N)) - \
                             np.outer(np.ones(NF0), muF0)) ** 2) / \
                   np.outer(np.ones(NF0), sigmaF00))
    HF0 = HF0fo * HF0 / \
          np.outer(np.ones(NF0), HF0fo.max(axis=0))
    
    if R==0:
        HM0 = 0
        WM0 = 0
    else:
        if HM0 is None:
            HM0 = np.abs(randn(R, N))
        else:
            if np.array(HM0).shape[0] == R and np.array(HM0).shape[1] == N:
                HM0 = np.array(HM0)
            else:
                print "Wrong dimensions for given HM0, \n"
                print "random initialization used instead"
            HM0 = np.abs(randn(R, N))
            
        if WM0 is None:
            WM0 = np.abs(randn(F, R))
        else:
            if np.array(WM0).shape[0] == F and np.array(WM0).shape[1] == R:
                WM0 = np.array(WM0)
            else:
                print "Wrong dimensions for given WM0, \n"
                print "random initialization used instead"
            WM0 = np.abs(randn(F, R))
            
    HM = HM0
    WM = WM0
    
    # Iterations to estimate the SIMM parameters:
    WPHI = WPHI0
    SF0 = np.maximum(np.dot(WF0, HF0), eps)
    SPHI = np.maximum(np.dot(WPHI, HPHI), eps)
    SM = np.maximum(np.dot(WM, HM), eps)
    hatSX = np.maximum(SF0 * SPHI + SM, eps)
    # temporary matrices
    tempNumFbyN = np.zeros([F, N])
    tempDenFbyN = np.zeros([F, N])
    
    # Array containing the reconstruction error after the update of each 
    # of the parameter matrices:
    recoError = np.zeros([numberOfIterations * 4 * 2 + NF0 * 2 + 1])
    recoError[0] = ISDistortion(SX, hatSX)
    if verbose:
        print "Reconstruction error at beginning: ", recoError[0]
    counterError = 1
    if displayEvolution:
        h1 = plt.figure(1)
        h2 = plt.figure(2)
        h3 = plt.figure(3)
        h4 = plt.figure(4)
        
    # Main loop for multiplicative updating rules:
    for n in np.arange(numberOfIterations):
        # order of re-estimation: HF0, HPHI, HM, HGAMMA, WM
        if verbose:
            print "iteration ", n, " over ", numberOfIterations
        if displayEvolution:
            plt.figure(1)
            h1.clf()
            #imageM(db(HF0))
            #plt.clim([np.amax(db(HF0))-100, np.amax(db(HF0))]);plt.draw();
            plt.plot(db(SX))
            plt.hold(True)
            plt.plot(db(hatSX),'r')
            plt.draw()
            ## h1.clf();
            ## imageM(HF0 * np.outer(np.ones([NF0, 1]),
            ##                       1 / (HF0.max(axis=0))));
            plt.figure(2)
            h2.clf()
            imageM(db(HPHI));plt.draw();
            plt.clim([db(HPHI).max()-100, db(HPHI).max()])
            
        # updating HF0:
        tempNumFbyN = (SPHI * SX) / np.maximum(hatSX ** 2, eps)
        tempDenFbyN = SPHI / np.maximum(hatSX, eps)
        # This to enable octave control
        ## HF0[np.arange(12 * stepNotes, NF0), :] \
        ##    = HF0[np.arange(12 * stepNotes, NF0), :] \
        ##      * (np.dot(WF0[:, np.arange(12 * stepNotes,
        ##                                 NF0)].T, tempNumFbyN) \
        ##         / np.maximum(
        ##     np.dot(WF0[:, np.arange(12 * stepNotes, NF0)].T,
        ##            tempDenFbyN) \
        ##     + lambdaHF0 * (- (alphaHF0 - 1.0) \
        ##                    / np.maximum(HF0[
        ##     np.arange(12 * stepNotes, NF0), :], eps) \
        ##                    + HF0[
        ##     np.arange(NF0 - 12 * stepNotes), :]),
        ##     eps)) ** omega
        ## 
        ## HF0[np.arange(12 * stepNotes), :] \
        ##    = HF0[np.arange(12 * stepNotes), :] \
        ##      * (np.dot(WF0[:, np.arange(12 * stepNotes)].T,
        ##               tempNumFbyN) /
        ##        np.maximum(
        ##         np.dot(WF0[:, np.arange(12 * stepNotes)].T,
        ##                tempDenFbyN), eps)) ** omega
        
        # normal update rules:
##        HF0 = HF0 * (np.dot(WF0.T, tempNumFbyN) / \
##                     np.maximum(np.dot(WF0.T, tempDenFbyN), eps)) ** omega
        HF0 = HF0 * (np.dot(WF0T, tempNumFbyN) / \
                     np.maximum(np.dot(WF0T, tempDenFbyN), eps)) ** omega
        
        if n < nbIterAdaptF0:
            HF0fo = np.copy(HF0)
            sumHF0fo = HF0fo.sum(axis=0)
            HF0fo = HF0fo / np.outer(np.ones(NF0), sumHF0fo)
            muF0 = np.argmax(HF0fo, axis=0)## np.dot(np.arange(NF0), HF0fo) # weighted mean, computed as value * nb_occurrences
            if displayEvolution:
                plt.figure(h4.number)
                h4.clf()
                plt.plot(muF0, '.')
                plt.axis('tight')
                plt.ylim([0,NF0-1])
                plt.draw()
            muF0 = medianFilter(muF0, scope = 10)
            if displayEvolution:
                plt.hold(True)
                plt.plot(muF0,'.g')
            sigmaF00 = sigmaF0[n]
            HF0fo = 1 / np.sqrt(2.0*np.pi*np.outer(np.ones(NF0), sigmaF00)) * \
                    np.exp(- 0.5 * ((np.outer(np.arange(NF0), np.ones(N)) - \
                                     np.outer(np.ones(NF0), muF0)) ** 2) / \
                           np.outer(np.ones(NF0), sigmaF00))
            HF0fo[-1,:] = HF0fo.max(axis=0)
            HF0 = HF0fo * HF0 / \
                  np.outer(np.ones(NF0), HF0fo[-1,:])
        
        SF0 = np.maximum(np.dot(WF0, HF0), eps)
        hatSX = np.maximum(SF0 * SPHI + SM, eps)
        recoError[counterError] = ISDistortion(SX, hatSX)
        
        if verbose:
            print "Reconstruction error difference after HF0   : ",
            print recoError[counterError] - recoError[counterError - 1]
        counterError += 1
        
        # updating HPHI
        tempNumFbyN = (SF0 * SX) / np.maximum(hatSX ** 2, eps)
        tempDenFbyN = SF0 / np.maximum(hatSX, eps)
##        HPHI = HPHI * (np.dot(WPHI.T, tempNumFbyN) / \
##                       np.maximum(np.dot(WPHI.T, tempDenFbyN), eps)) ** omega
        HPHI = HPHI * (np.dot(WPHIT, tempNumFbyN) / \
                       np.maximum(np.dot(WPHIT, tempDenFbyN), eps)) ** omega
        
        # post processing : Monte Carlo Approx! yeah... almost anyway
        if n < nbIterAdaptFormant:
            if displayEvolution:
                plt.figure(h3.number)
                h3.clf()
                
            muAbsolute = np.zeros([4, N])
            
            for nn in range(numberOfFormants):
                HPHIfo = HPHI[formantRanges[nn], :]
                sumHPHIfo = HPHIfo.sum(axis=0)
                HPHIfo = HPHIfo / np.outer(np.ones(nbElPerFormant), \
                                           sumHPHIfo)
                muAbsolute[nn] = np.argmax(HPHIfo, axis=0) + \
                                 formantRanges[nn][0]
                muAbsolute[nn] = medianFilter(muAbsolute[nn], scope = 10)
                
            
            muAbsolute = muAbsolute[np.argsort(poleFrq[np.int32(muAbsolute)], axis=0),
                                    rangeInMapping]
            muNew = mapFormantToOther[np.int32(muAbsolute),
                                      rangeInRemapping]
            
            for nn in range(numberOfFormants):
                HPHIfo = HPHI[formantRanges[nn], :]
                sumHPHIfo = HPHIfo.sum(axis=0)
                HPHIfo = HPHIfo / np.outer(np.ones(nbElPerFormant), sumHPHIfo)
                ## mu = np.argmax(HPHIfo, axis=0)
                ## mu = medianFilter(mu, scope = 10)
                mu = muNew[nn] - formantRanges[nn][0]
                # np.dot(np.arange(nbElPerFormant), HPHIfo)
                # weighted mean, computed as value * nb_occurrences
                sigmaFormant0 = sigmaFormant[n]
                ## print sigmaFormant0
                HPHIfo = 1 / np.sqrt(2.0*np.pi*np.outer(np.ones(nbElPerFormant),
                                                        sigmaFormant0)) * \
                         np.exp(- 0.5 * ((np.outer(np.arange(nbElPerFormant),
                                                   np.ones(N)) - \
                                          np.outer(np.ones(nbElPerFormant),
                                                   mu)) ** 2) / \
                                np.outer(np.ones(nbElPerFormant), sigmaFormant0))
                HPHI[formantRanges[nn], :] = HPHIfo * HPHI[formantRanges[nn], :] / \
                                             np.outer(np.ones(nbElPerFormant), \
                                                      HPHIfo.max(axis=0))
                ##HPHIfo * np.outer(np.ones(nbElPerFormant), sumHPHIfo)
                if displayEvolution:
                    plt.plot(poleFrq[np.int32(mu + formantRanges[nn][0])], '.')
                    plt.axis('tight')
                    plt.ylim([0, poleFrq[-1]])
                    plt.hold(True)
                    plt.draw()
                    
        
        sumHPHI = np.sum(HPHI, axis=0)
        HPHI[:, sumHPHI>0] = HPHI[:, sumHPHI>0] / np.outer(np.ones(K), sumHPHI[sumHPHI>0])
        HF0 = HF0 * np.outer(np.ones(NF0), sumHPHI)
        
        SF0 = np.maximum(np.dot(WF0, HF0), eps)
        SPHI = np.maximum(np.dot(WPHI, HPHI), eps)
        hatSX = np.maximum(SF0 * SPHI + SM, eps)
        
        recoError[counterError] = ISDistortion(SX, hatSX)
        
        if verbose:
            print "Reconstruction error difference after HPHI  : ", \
                  recoError[counterError] - recoError[counterError - 1]
        counterError += 1
        
        if R>0:
            # updating HM
            tempNumFbyN = SX / np.maximum(hatSX ** 2, eps)
            tempDenFbyN = 1 / np.maximum(hatSX, eps)
            HM = HM * (np.dot(WM.T, tempNumFbyN) / \
                       np.maximum(np.dot(WM.T, tempDenFbyN), eps)) ** omega
            
            SM = np.maximum(np.dot(WM, HM), eps)
            hatSX = np.maximum(SF0 * SPHI + SM, eps)
            
            recoError[counterError] = ISDistortion(SX, hatSX)
            
            if verbose:
                print "Reconstruction error difference after HM    : ", \
                      recoError[counterError] - recoError[counterError - 1]
            counterError += 1
            
            # updating WM, after a certain number of iterations
            # (here, after 1 iteration)
            if n > 0: # this test can be used such that WM is updated only
                      # after a certain number of iterations
                tempNumFbyN = SX / np.maximum(hatSX ** 2, eps)
                tempDenFbyN = 1 / np.maximum(hatSX, eps)
                WM = WM * (np.dot(tempNumFbyN, HM.T) /
                                      np.maximum(np.dot(tempDenFbyN, HM.T),
                                                 eps)) ** omega
                
                sumWM = np.sum(WM, axis=0)
                WM[:, sumWM>0] = (WM[:, sumWM>0] /
                                  np.outer(np.ones(F),sumWM[sumWM>0]))
                HM = HM * np.outer(sumWM, np.ones(N))
                
                SM = np.maximum(np.dot(WM, HM), eps)
                hatSX = np.maximum(SF0 * SPHI + SM, eps)
                
                recoError[counterError] = ISDistortion(SX, hatSX)
                
                if verbose:
                    print "Reconstruction error difference after WM    : ",
                    print recoError[counterError] - recoError[counterError - 1]
                counterError += 1
                
    return HPHI, HF0, HM, WM, recoError

def ARPIMM(SX, W, H0=None, nbIterations=100, dispEvol=True, verbose=True):
    """
    ARPIMM : no sparsity constraints. Brute estimation. 
    """
    eps = 10 ** -50
    
    F, N = SX.shape
    
    P = len(W) # W is a list of basis matrices
    K = np.zeros(P) # each matrix size
    for p in range(P):
        if W[p].shape[0] == F: K[p] = W[p].shape[1]
        else: raise ValueError('Size of W[%d] not same as input SX' %(p))
    
    if H0 == None or len(H0)!=P:
        H = {}
        for p in range(P):
            H[p] = np.random.rand(K[p], N)**2
    else:
        H = {}
        for p in range(P):
            if H0[p].shape[0] == K[p]:
                H[p] = H0[p]
            else: raise ValueError("Size of H0[%d] not same as W[%d]" %(p, p))
    
    S = []
    for p in range(P):
        S.append(np.dot(W[p],H[p]))
    
    if dispEvol:
        import matplotlib.pyplot as plt
        from imageMatlab import imageM
        plt.ion()
        print "Is the display interactive? ", plt.isinteractive()
        plt.figure(1);
        plt.clf()
        for p in range(P):
            plt.subplot(P,1,p+1)
            if H[p].shape[1]==1:
                plt.plot(H[p])
            else:
                imageM(db(H[p]))
                if p!=0:
                    plt.clim([-30,0])
                ##plt.colorbar()
        plt.draw()
    
    hatSX = np.maximum(np.prod(S, axis=0), eps)
    
    recoError = np.zeros(nbIterations*P)
    recoError[0] = ISDistortion(SX, hatSX)
    if verbose: print recoError[0]
    
    tempNum = np.zeros([F,N])
    tempDen = np.zeros([F,N])
    for n in range(nbIterations):
        if verbose: print 'iteration', n
        for p in range(P):
            ##tempNum = np.prod(S[:p], axis=0) * \
            ##          np.prod(S[(p+1):], axis=0) * \
            ##          SX / np.maximum((hatSX ** 2), eps)
            ##tempDen = np.prod(S[:p], axis=0) * \
            ##          np.prod(S[(p+1):], axis=0) / hatSX
            tempNum = SX / np.maximum(hatSX * S[p], eps)
            tempDen = 1 / np.maximum(S[p], eps)
            
            H[p] = H[p] * np.dot(W[p].T, tempNum) / \
                   np.maximum(np.dot(W[p].T, tempDen), eps)
            
            if p!= 0:
                sumH = H[p].sum(axis=0)
                H[p] = H[p] / np.outer(np.ones(K[p]), sumH)
                H[0] = H[0] * np.outer(np.ones(K[0]), sumH)
                S[0] = np.dot(W[0],H[0])
            
            S[p] = np.dot(W[p],H[p])
            hatSX = np.maximum(np.prod(S, axis=0), eps)
            
            recoError[n*P+p] = ISDistortion(SX, hatSX)
            if verbose: print 'error after update nb ', n*P+p, ':', recoError[n*P+p]
        
        if dispEvol:
            plt.figure(1)
            plt.clf()
            for p in range(P):
                plt.subplot(P,1,p+1)
                if H[p].shape[1]==1:
                    plt.plot((H[p]))
                else:
                    imageM(db(H[p]))
                    if p!=0:
                        plt.clim([-30, 0])
                    ## plt.colorbar()
            plt.draw()
            plt.figure(2)
            plt.clf()
            imageM(db(hatSX))
            plt.draw()
                
    return H, recoError

def SparARPIMM(SX, W, stepNotes, H0=None, nbIterations=200,
               scopeMedian=10,
               dispEvol=True, verbose=True,
               poleFrq=None, poleAmp=None, smoothIt=True):
    
    eps = 10 ** -50
    
    F, N = SX.shape
    
    P = len(W) # W is a list of basis matrices
    K = np.zeros(P) # each matrix size
    for p in range(P):
        if W[p].shape[0] == F: K[p] = W[p].shape[1]
        else: raise ValueError('Size of W[%d] not same as input SX' %(p))
    
    if H0 == None or len(H0)!=P:
        H = {}
        for p in range(P):
            H[p] = np.random.rand(K[p], N)**2
    else:
        H = {}
        for p in range(P):
            if H0[p].shape[0] == K[p]:
                H[p] = H0[p]
            else: raise ValueError("Size of H0[%d] not same as W[%d]" %(p, p))
    
    S = []
    for p in range(P):
        S.append(np.dot(W[p],H[p]))
    
    if dispEvol:
        import matplotlib.pyplot as plt
        from imageMatlab import imageM
        plt.ion()
        print "Is the display interactive? ", plt.isinteractive()
        plt.figure(1);
        plt.clf()
        for p in range(P):
            plt.subplot(P,1,p+1)
            imageM(db(H[p]))
            if p!=0:
                plt.clim([-30,0])
            plt.colorbar()
        plt.draw()
    
    nbUncstIter = 0
    nbEndIter = 5
    nbIterSig = np.maximum(nbUncstIter+nbEndIter, \
                           nbIterations - (nbUncstIter+nbEndIter)) 
    # a sequence of sigmas for the gauss model for H
    sigma = np.zeros(nbIterSig)
    sigmaInf = 9.0
    sigma0 = (K.max()) ** 2
    for n in range(nbIterSig):
        ##sigma[n] = sigma0 + (sigmaInf - sigma0) / \
        ##           (nbIterations - 1.0) * n
        sigma[n] = np.exp(np.log(sigma0) + \
                          (np.log(sigmaInf) - \
                           np.log(sigma0)) / \
                          (nbIterSig - 1.0) * n)

    ##plt.figure();plt.plot(sigma)
    ##raw_input()
    
    hatSX = np.maximum(np.prod(S, axis=0), eps)
    
    recoError = np.zeros(nbIterations*P)
    recoError[0] = ISDistortion(SX, hatSX)
    if verbose: print "Initial error: "+str(recoError[0])
    
    tempNum = np.zeros([F,N])
    tempDen = np.zeros([F,N])
    for n in range(nbIterations):
        if verbose: print 'iteration', n, ' of ', nbIterations
        for p in range(P):
            ##tempNum = np.prod(S[:p], axis=0) * \
            ##          np.prod(S[(p+1):], axis=0) * \
            ##          SX / np.maximum((hatSX ** 2), eps)
            ##tempDen = np.prod(S[:p], axis=0) * \
            ##          np.prod(S[(p+1):], axis=0) / hatSX
            tempNum = SX / np.maximum((hatSX * S[p]), eps)
            tempDen = 1 / np.maximum(S[p], eps)
            
            H[p] = H[p] * np.dot(W[p].T, tempNum) / \
                    np.maximum(np.dot(W[p].T, tempDen), eps)
            
            # enforcing sparsity
            # take muH as the argmax of each column (the mode):
            ##muH = np.argmax(H[p][:-1,:], axis=0)
            ##if dispEvol:
            ##    plt.figure(1)
            ##    plt.subplot(P,1,p+1)
            ##    plt.plot(muH, 'b')
            ##    plt.axis('tight')
            ##    plt.draw()
            
            # take muH as the barycenter (mean of the distribution):
            if n >= nbUncstIter and n < nbIterations-nbEndIter:
                ncstIter = n-nbUncstIter
                if p==0:
                    ##muH = np.dot(np.arange(K[p]-1) * \
                    ##             (np.arange(K[p]-1, 0, -1))**2, \
                    ##             H[p][:-1,:]) / \
                    ##             np.dot((np.arange(K[p]-1, 0, -1))**2,
                    ##                    np.maximum(H[p][:-1,:], eps))
                    muH = np.dot(np.arange(K[p]-1) * \
                                 (np.arange(K[p]-1, 0, -1))**2, \
                                 H[p][:-1,:]) / \
                                 np.dot((np.arange(K[p]-1, 0, -1))**2,
                                        np.maximum(H[p][:-1,:], eps))
                else:
                    muH = np.dot(np.arange(K[p]-1), H[p][:-1,:]) / \
                          np.sum(np.maximum(H[p][:-1,:], eps), axis=0)
                if dispEvol:
                    plt.figure(1)
                    plt.subplot(P,1,p+1)
                    plt.plot(muH, 'g')
                    plt.axis('tight')
                    plt.draw()
                
                # smooth the obtained sequence:
                if smoothIt:
                    muH = medianFilter(muH, scope=scopeMedian)
                
                # weighted median, to avoid taking into account
                # low energy coefficients
                ## does not work, problem with median ... TODO!
                ##muH = medianWeightedFilter(muH,
                ##                           H[p][np.int32(np.round(muH)),
                ##                                range(N)],
                ##                           scope=10)
                
                if dispEvol:
                    plt.figure(1)
                    plt.subplot(P,1,p+1)
                    plt.plot(muH, 'k')
                    plt.axis('tight')
                    plt.draw()
                
                # weights to get sparse:
                Hp = np.exp(- 0.5 * ((np.outer(np.arange(K[p]),
                                               np.ones(N)) - \
                                      np.outer(np.ones(K[p]),
                                               muH)) ** 2) / \
                            np.outer(np.ones(K[p]), sigma[ncstIter]))
                if True or p==0:
                    # take into account last el. in W[0],
                    # supposedly WF0, which corresponds to the
                    # unvoiced element. 
                    Hp[-1,:] = Hp.max(axis=0)
            
                H[p] = Hp * H[p] / \
                       np.outer(np.ones(K[p]), Hp.max(axis=0))
            
            if p!= 0:
                sumH = H[p].sum(axis=0)
                H[p] = H[p] / np.outer(np.ones(K[p]), sumH)
                H[0] = H[0] * np.outer(np.ones(K[0]), sumH)
                S[0] = np.dot(W[0],H[0])
            
            S[p] = np.dot(W[p],H[p])
            hatSX = np.maximum(np.prod(S, axis=0), eps)
            
            recoError[n*P+p] = ISDistortion(SX, hatSX)
            if verbose:
                print 'error after update nb ', n*P+p, \
                      ':', recoError[n*P+p], ' evol compared with previous: ', recoError[n*P+p] - recoError[n*P+p-1]
            
        if dispEvol:
            plt.figure(1)
            plt.clf()
            for p in range(P):
                plt.subplot(P,1,p+1)
                imageM(db(np.maximum(H[p],eps)))
                if p!=0:
                    plt.clim([-30, 0])
                ## plt.colorbar()
            plt.draw()
            plt.figure(2)
            plt.clf()
            imageM(db(hatSX))
            plt.draw()
            ##raw_input("hit for heat")
        
    return H, recoError

def SFSNMF(SX,
           W, WR, stepNotes,
           G0=None,
           H0=None,
           nbIterations=200,
           scopeMedian=10,
           dispEvol=True, verbose=True,
           poleFrq=None, poleAmp=None, smoothIt=True):
    """SFSNMF
    source/filter sparse non-negative matrix factorization
    
    revised version from ICASSP 2011, to journal article on FHMM
    
    """
    
    eps = 10 ** -50
    
    F, N = SX.shape
    
    # parsing W, list of matrices of spectral shapes
    # one for each formant
    #    W[0] should be the source spectral shapes
    P = len(W) # W is a list of basis matrices
    K = np.zeros(P) # each matrix size
    for p in range(P):
        if W[p].shape[0] == F: K[p] = W[p].shape[1]
        else: raise ValueError('Size of W[%d] not same as input SX' %(p))
    
    if WR.shape[0] == F: KR = WR.shape[1]
    else: raise ValueError('Size of WR not same as input SX')
    
    # parsing initial G0
    if G0 == None or len(G0)!=P:
        G = {}
        warnings.warn("Provided G0 None or badly initialized.")
        for p in range(P):
            G[p] = np.random.rand(K[p], N)**2
            G[p] = normalize(G[p], axis=0)
    else:
        G = {}
        for p in range(P):
            if G0[p].shape[0] == K[p]:
                G[p] = normalize(G0[p], axis=0)
            else: raise ValueError("Size of G0[%d] not same as W[%d]" %(p, p))
    
    # energy parameters:
    if H0 is None or H0.size != N:
        H = SX.sum(axis=0)
    else:
        H = np.copy(H0)
    # recording condition parameters:
    GR = np.ones(KR)
    
    # a list of intermediate component matrices
    S = []
    for p in range(P):
        S.append(np.dot(W[p],G[p]))
    
    # displaying 
    if dispEvol:
        import matplotlib.pyplot as plt
        plt.rcParams['image.interpolation'] = 'nearest'
        plt.rcParams['image.origin'] = 'lower'
        plt.ion()
        print "Is the display interactive? ", plt.isinteractive()
        plt.figure(1);
        plt.clf()
        for p in range(P):
            plt.subplot(P,1,p+1)
            plt.imshow(db(G[p]))
            if p!=0:
                plt.clim([-30,0])
            plt.colorbar()
        plt.draw()
        
    
    nbUncstIter = 0
    nbEndIter = 5
    nbIterSig = np.maximum(nbUncstIter+nbEndIter, \
                           nbIterations - (nbUncstIter+nbEndIter)) 
    # a sequence of sigmas for the gauss model for H
    sigma = np.zeros(nbIterSig)
    sigmaInf = 9.0
    sigma0 = (K.max()) ** 2
    # log of sigma linearly decreasing over iterations
    for n in range(nbIterSig):
        sigma[n] = np.exp(np.log(sigma0) + \
                          (np.log(sigmaInf) - \
                           np.log(sigma0)) / \
                          (nbIterSig - 1.0) * n)
    
    # hatSX is the estimated SX
    #    energy * recordFilter * source * vocalFilter
    hatSX = H * np.vstack(np.dot(WR,GR)) * np.prod(S, axis=0)
    hatSX = np.maximum(hatSX, eps)
    
    if dispEvol:
        # display also initial estimate
        plt.figure(2)
        plt.clf()
        plt.imshow(db(hatSX))
        plt.draw()
    
    recoError = np.zeros(nbIterations*P)
    recoError[0] = ISDistortion(SX, hatSX)
    if verbose: print "Initial error: "+str(recoError[0])
    
    # useful temporary numerator and denominator
    # for the NMF algorithm
    tempNum = np.zeros([F,N])
    tempDen = np.zeros([F,N])
    
    for n in range(nbIterations):
        if verbose: print 'iteration', n, ' of ', nbIterations
        for p in range(P):
            tempNum = SX / np.maximum((hatSX * S[p]), eps)
            tempDen = 1 / np.maximum(S[p], eps)
            
            G[p] = G[p] * np.dot(W[p].T, tempNum) / \
                    np.maximum(np.dot(W[p].T, tempDen), eps)
            
            # take muH as the barycenter (mean of the distribution):
            if n >= nbUncstIter and n < nbIterations-nbEndIter:
                ncstIter = n-nbUncstIter
                if p==0:
                    muG = np.dot(np.arange(K[p]-1) * \
                                 (np.arange(K[p]-1, 0, -1))**2, \
                                 G[p][:-1,:]) / \
                                 np.dot((np.arange(K[p]-1, 0, -1))**2,
                                        np.maximum(G[p][:-1,:], eps))
                else:
                    muG = np.dot(np.arange(K[p]-1), G[p][:-1,:]) / \
                          np.sum(np.maximum(G[p][:-1,:], eps), axis=0)
                if dispEvol:
                    plt.figure(1)
                    plt.subplot(P+2,1,p+1)
                    plt.plot(muG, 'g')
                    plt.axis('tight')
                    plt.draw()
                
                # smooth the obtained sequence:
                if smoothIt:
                    muG = medianFilter(muG, scope=scopeMedian)
                
                # weighted median, to avoid taking into account
                # low energy coefficients
                ## does not work, problem with median ... TODO!
                ##muH = medianWeightedFilter(muH,
                ##                           H[p][np.int32(np.round(muH)),
                ##                                range(N)],
                ##                           scope=10)
                
                if dispEvol:
                    plt.figure(1)
                    plt.subplot(P+2,1,p+1)
                    plt.plot(muG, 'k')
                    plt.axis('tight')
                    plt.draw()
                
                # weights to get sparse:
                Gp = np.exp(- 0.5 * ((np.outer(np.arange(K[p]),
                                               np.ones(N)) - \
                                      np.outer(np.ones(K[p]),
                                               muG)) ** 2) / \
                            np.outer(np.ones(K[p]), sigma[ncstIter]))
                if True or p==0:
                    # take into account last el. in W[p],
                    # which corresponds to the
                    # unvoiced element or flat freq. response. 
                    Gp[-1,:] = Gp.max(axis=0)
            
                G[p] = Gp * G[p] / \
                       np.outer(np.ones(K[p]), Gp.max(axis=0))
            
            sumG = G[p].max(axis=0)# G[p].sum(axis=0)
            G[p] = G[p] / np.outer(np.ones(K[p]), sumG)
            H = H * sumG
            
            S[p] = np.dot(W[p],G[p])
            hatSX = H * np.vstack(np.dot(WR,GR)) * np.prod(S, axis=0)
            hatSX = np.maximum(hatSX, eps)
            
            # updating recording condition filter
            tempNum = SX / np.maximum(hatSX * np.vstack(np.dot(WR, GR)), eps)
            tempDen = N / np.maximum(np.dot(WR, GR), eps)
            GR = GR * np.dot(WR.T, np.sum(tempNum, axis=1)) / \
                 np.maximum(np.dot(WR.T, tempDen), eps)

            sumG = GR.sum()
            GR = GR / sumG
            H = H * sumG
            
            hatSX = H * np.vstack(np.dot(WR,GR)) * np.prod(S, axis=0)
            hatSX = np.maximum(hatSX, eps)
            
            # updating energy component
            H = np.mean(SX / np.maximum(np.vstack(np.dot(WR,GR)) * \
                                        np.prod(S, axis=0), eps), \
                        axis=0)
            
            hatSX = H * np.vstack(np.dot(WR,GR)) * np.prod(S, axis=0)
            hatSX = np.maximum(hatSX, eps)
            
            recoError[n*P+p] = ISDistortion(SX, hatSX)
            if verbose:
                print 'error after update nb ', n*P+p, \
                      ':', recoError[n*P+p], ' evol compared with previous: ', \
                      recoError[n*P+p] - recoError[n*P+p-1]
            
        if dispEvol:
            plt.figure(1)
            plt.clf()
            for p in range(P):
                plt.subplot(P+2,1,p+1)
                plt.imshow(db(np.maximum(G[p],eps)))
                if p!=0:
                    plt.clim([-30, 0])
                ## plt.colorbar()
            plt.subplot(P+2,1,P+1)
            plt.plot(H)
            plt.subplot(P+2,1,P+2)
            plt.plot(db(np.dot(WR,GR)))
            plt.draw()
            plt.figure(2)
            plt.clf()
            plt.imshow(db(hatSX))
            plt.draw()
            ##raw_input("hit for heat")
        
    return G, GR, H, recoError
    

def singleMatGauss(SX, W, mu0=None, nbIterations=20,
                   dispEvol=True, verbose=True):
    eps = 10 ** -50
    
    F, N = SX.shape
    if W.shape[0] != F:
        raise ValueError("The shape of W %d x %d does not fit the shape of SX %d x %d" \
                         %(W.shape[0], W.shape[1], SX.shape[0], SX.shape[1]))
    
    K = W.shape[1]
    
    # a matrix to generate the H
    vectorOfH = np.arange(K)
    matrixForH = np.outer(vectorOfH, np.ones(N))
    
    # a sequence of sigmas for the gauss model for H
    sigma = np.zeros(nbIterations+1)
    sigmaInf = 1.0
    sigma0 = K
    # This does not work, hard to get out of initial values... : sigma0 = 1 #K/4.0 # for debug
    for n in range(nbIterations):
        sigma[n] = np.exp(np.log(sigma0) + (np.log(sigmaInf) - np.log(sigma0)) / (nbIterations - 1.0) * n)
    
    if mu0 is None:
        mu = np.random.rand(N) * K
    else:
        mu = mu0.copy()
    
    H = normalDistributionMat(matrixForH, mu, sigma[0]*np.ones(N))
    
    hatSX = np.maximum(np.dot(W, H), eps)
    recoError = np.zeros(nbIterations+1)
    recoError[0] = ISDistortion(SX, hatSX)
    if dispEvol:
        import matplotlib as mpl
        import matplotlib.pyplot as plt
        from imageTools import imageM
        plt.figure(1)
        plt.clf()
        imageM(db(hatSX))
        
    if verbose: print "Reconstruction error:", recoError[0]
    
    tempkWH = np.zeros([F, N])
    tempNum = np.zeros([F, N])
    tempDen = np.zeros([F, N])
    for niter in range(nbIterations):
        tempkWH = np.dot(np.dot(W, np.diag(np.arange(K))), H)
        tempNum = SX / (hatSX ** 2) * tempkWH
        tempDen = (tempkWH + np.outer(np.ones(F), mu) * SX) / hatSX
        
        mu *= (np.sum(tempNum, axis=0) + F * mu) / \
              (np.sum(tempDen, axis=0))
        mu = np.maximum(mu, 1.0)
        
        H = normalDistributionMat(matrixForH, mu, sigma[niter]*np.ones(N))
        hatSX = np.maximum(np.dot(W, H), eps)
        recoError[niter+1] = ISDistortion(SX, hatSX)
        if verbose: print "Reconstruction error :", recoError[niter+1]
        if dispEvol:
            plt.figure(1)
            plt.clf()
            imageM(db(hatSX))
            plt.draw()
            plt.figure(2)
            plt.clf()
            imageM((H))
            plt.hold(True)
            plt.plot(mu)
            plt.axis('tight')
            plt.draw()
        
    return mu, recoError
